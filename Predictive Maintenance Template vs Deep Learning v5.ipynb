{"nbformat_minor": 2, "cells": [{"source": "# Deep Learning for Predictive Maintenance\n\nDeep learning has proven to show superior performance in certain domains such as object recognition and image classification. It is has also gained popularity in  domains such as finance where time-series data plays an important role. Predictive Maintenance is also a domain where data is collected over time to monitor the state of an asset with the goal of finding patterns to predict failures which can also benefit from certain deep learning algorithms. \nAmong the deep learning methods, Long Short Time Memory [(LSTM)](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) networks are especially appealing to the predictive maintenance domain due to the fact that they are very good at learning from sequences. This fact lends itself to their applications using time series data by making it possible to look back for longer periods of time to detect failure patterns. \n\nIn this notebook, we build an LSTM network for the data set and scenerio described at [Predictive Maintenance Template](https://gallery.cortanaintelligence.com/Collection/Predictive-Maintenance-Template-3) to predict remaining useful life of aircraft engines. In summary, the template uses simulated aircraft sensor values to predict when an aircraft engine will fail in the future so that maintenance can be planned in advance. \n\nThis notebook serves as a tutorial for beginners looking to apply deep learning in predictive maintenance domains and uses a simple scenario where only one data source (sensor values) is used to make predictions. In more advanced predictive maintenance scenarios such as in [Predictive Maintenance Modelling Guide](https://gallery.cortanaintelligence.com/Notebook/Predictive-Maintenance-Modelling-Guide-R-Notebook-1), there are many other data sources such as maintenance records, error logs etc. which may require different types of treatments to be used in the deep learning networks. Since predictive maintenance is not a typical domain for deep learning, its application is an open area of research. \n\nThis notebook uses [keras](https://keras.io/) deep learning library.", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"execution_count": 55, "cell_type": "code", "source": "!pip install --upgrade pip\n!pip install keras\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nnp.random.seed(12345)  # setting seed for reproducibility\nPYTHONHASHSEED = 0\nfrom sklearn import preprocessing\nfrom sklearn.metrics import confusion_matrix, recall_score, precision_score\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, LSTM, Activation\n%matplotlib inline", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Requirement already up-to-date: pip in /home/nbcommon/anaconda3_410/lib/python3.5/site-packages\nRequirement already satisfied: keras in /home/nbcommon/anaconda3_410/lib/python3.5/site-packages\nRequirement already satisfied: pyyaml in /home/nbcommon/anaconda3_410/lib/python3.5/site-packages (from keras)\nRequirement already satisfied: theano in /home/nbcommon/anaconda3_410/lib/python3.5/site-packages (from keras)\nRequirement already satisfied: six in /home/nbcommon/anaconda3_410/lib/python3.5/site-packages (from keras)\nRequirement already satisfied: numpy>=1.9.1 in /home/nbcommon/anaconda3_410/lib/python3.5/site-packages (from theano->keras)\nRequirement already satisfied: scipy>=0.14 in /home/nbcommon/anaconda3_410/lib/python3.5/site-packages (from theano->keras)\n"}], "metadata": {"collapsed": false}}, {"source": "## Data Ingestion\nIn the following, we ingest the training, test and ground truth datasets from azure storage.", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"execution_count": 2, "cell_type": "code", "source": "!wget http://azuremlsamples.azureml.net/templatedata/PM_train.txt \n!wget http://azuremlsamples.azureml.net/templatedata/PM_test.txt\n!wget http://azuremlsamples.azureml.net/templatedata/PM_truth.txt ", "outputs": [{"output_type": "stream", "name": "stdout", "text": "--2017-06-06 18:00:26--  http://azuremlsamples.azureml.net/templatedata/PM_train.txt\nResolving webproxy (webproxy)... 100.116.22.55\nConnecting to webproxy (webproxy)|100.116.22.55|:3128... connected.\nProxy request sent, awaiting response... 200 OK\nLength: 3515356 (3.4M) [text/plain]\nSaving to: 'PM_train.txt'\n\nPM_train.txt        100%[===================>]   3.35M  20.2MB/s    in 0.2s    \n\n2017-06-06 18:00:27 (20.2 MB/s) - 'PM_train.txt' saved [3515356/3515356]\n\n--2017-06-06 18:00:27--  http://azuremlsamples.azureml.net/templatedata/PM_test.txt\nResolving webproxy (webproxy)... 100.116.22.55\nConnecting to webproxy (webproxy)|100.116.22.55|:3128... connected.\nProxy request sent, awaiting response... 200 OK\nLength: 2228855 (2.1M) [text/plain]\nSaving to: 'PM_test.txt'\n\nPM_test.txt         100%[===================>]   2.12M  --.-KB/s    in 0.02s   \n\n2017-06-06 18:00:27 (89.7 MB/s) - 'PM_test.txt' saved [2228855/2228855]\n\n--2017-06-06 18:00:27--  http://azuremlsamples.azureml.net/templatedata/PM_truth.txt\nResolving webproxy (webproxy)... 100.116.22.55\nConnecting to webproxy (webproxy)|100.116.22.55|:3128... connected.\nProxy request sent, awaiting response... 200 OK\nLength: 429 [text/plain]\nSaving to: 'PM_truth.txt'\n\nPM_truth.txt        100%[===================>]     429  --.-KB/s    in 0s      \n\n2017-06-06 18:00:27 (93.3 MB/s) - 'PM_truth.txt' saved [429/429]\n\n"}], "metadata": {"collapsed": false}}, {"execution_count": 26, "cell_type": "code", "source": "# read training data \ntrain_df = pd.read_csv('PM_train.txt', sep=\" \", header=None)\ntrain_df.drop(train_df.columns[[26, 27]], axis=1, inplace=True)\ntrain_df.columns = ['id', 'cycle', 'setting1', 'setting2', 'setting3', 's1', 's2', 's3',\n                     's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14',\n                     's15', 's16', 's17', 's18', 's19', 's20', 's21']", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 27, "cell_type": "code", "source": "# read test data\ntest_df = pd.read_csv('PM_test.txt', sep=\" \", header=None)\ntest_df.drop(test_df.columns[[26, 27]], axis=1, inplace=True)\ntest_df.columns = ['id', 'cycle', 'setting1', 'setting2', 'setting3', 's1', 's2', 's3',\n                     's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14',\n                     's15', 's16', 's17', 's18', 's19', 's20', 's21']", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 28, "cell_type": "code", "source": "# read ground truth data\ntruth_df = pd.read_csv('PM_truth.txt', sep=\" \", header=None)\ntruth_df.drop(truth_df.columns[[1]], axis=1, inplace=True)", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 7, "cell_type": "code", "source": "train_df = train_df.sort_values(['id','cycle'])\ntrain_df.head()", "outputs": [{"execution_count": 7, "output_type": "execute_result", "data": {"text/plain": "   id  cycle  setting1  setting2  setting3      s1      s2       s3       s4  \\\n0   1      1   -0.0007   -0.0004     100.0  518.67  641.82  1589.70  1400.60   \n1   1      2    0.0019   -0.0003     100.0  518.67  642.15  1591.82  1403.14   \n2   1      3   -0.0043    0.0003     100.0  518.67  642.35  1587.99  1404.20   \n3   1      4    0.0007    0.0000     100.0  518.67  642.35  1582.79  1401.87   \n4   1      5   -0.0019   -0.0002     100.0  518.67  642.37  1582.85  1406.22   \n\n      s5   ...        s12      s13      s14     s15   s16  s17   s18    s19  \\\n0  14.62   ...     521.66  2388.02  8138.62  8.4195  0.03  392  2388  100.0   \n1  14.62   ...     522.28  2388.07  8131.49  8.4318  0.03  392  2388  100.0   \n2  14.62   ...     522.42  2388.03  8133.23  8.4178  0.03  390  2388  100.0   \n3  14.62   ...     522.86  2388.08  8133.83  8.3682  0.03  392  2388  100.0   \n4  14.62   ...     522.19  2388.04  8133.80  8.4294  0.03  393  2388  100.0   \n\n     s20      s21  \n0  39.06  23.4190  \n1  39.00  23.4236  \n2  38.95  23.3442  \n3  38.88  23.3739  \n4  38.90  23.4044  \n\n[5 rows x 26 columns]", "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th><\/th>\n      <th>id<\/th>\n      <th>cycle<\/th>\n      <th>setting1<\/th>\n      <th>setting2<\/th>\n      <th>setting3<\/th>\n      <th>s1<\/th>\n      <th>s2<\/th>\n      <th>s3<\/th>\n      <th>s4<\/th>\n      <th>s5<\/th>\n      <th>...<\/th>\n      <th>s12<\/th>\n      <th>s13<\/th>\n      <th>s14<\/th>\n      <th>s15<\/th>\n      <th>s16<\/th>\n      <th>s17<\/th>\n      <th>s18<\/th>\n      <th>s19<\/th>\n      <th>s20<\/th>\n      <th>s21<\/th>\n    <\/tr>\n  <\/thead>\n  <tbody>\n    <tr>\n      <th>0<\/th>\n      <td>1<\/td>\n      <td>1<\/td>\n      <td>-0.0007<\/td>\n      <td>-0.0004<\/td>\n      <td>100.0<\/td>\n      <td>518.67<\/td>\n      <td>641.82<\/td>\n      <td>1589.70<\/td>\n      <td>1400.60<\/td>\n      <td>14.62<\/td>\n      <td>...<\/td>\n      <td>521.66<\/td>\n      <td>2388.02<\/td>\n      <td>8138.62<\/td>\n      <td>8.4195<\/td>\n      <td>0.03<\/td>\n      <td>392<\/td>\n      <td>2388<\/td>\n      <td>100.0<\/td>\n      <td>39.06<\/td>\n      <td>23.4190<\/td>\n    <\/tr>\n    <tr>\n      <th>1<\/th>\n      <td>1<\/td>\n      <td>2<\/td>\n      <td>0.0019<\/td>\n      <td>-0.0003<\/td>\n      <td>100.0<\/td>\n      <td>518.67<\/td>\n      <td>642.15<\/td>\n      <td>1591.82<\/td>\n      <td>1403.14<\/td>\n      <td>14.62<\/td>\n      <td>...<\/td>\n      <td>522.28<\/td>\n      <td>2388.07<\/td>\n      <td>8131.49<\/td>\n      <td>8.4318<\/td>\n      <td>0.03<\/td>\n      <td>392<\/td>\n      <td>2388<\/td>\n      <td>100.0<\/td>\n      <td>39.00<\/td>\n      <td>23.4236<\/td>\n    <\/tr>\n    <tr>\n      <th>2<\/th>\n      <td>1<\/td>\n      <td>3<\/td>\n      <td>-0.0043<\/td>\n      <td>0.0003<\/td>\n      <td>100.0<\/td>\n      <td>518.67<\/td>\n      <td>642.35<\/td>\n      <td>1587.99<\/td>\n      <td>1404.20<\/td>\n      <td>14.62<\/td>\n      <td>...<\/td>\n      <td>522.42<\/td>\n      <td>2388.03<\/td>\n      <td>8133.23<\/td>\n      <td>8.4178<\/td>\n      <td>0.03<\/td>\n      <td>390<\/td>\n      <td>2388<\/td>\n      <td>100.0<\/td>\n      <td>38.95<\/td>\n      <td>23.3442<\/td>\n    <\/tr>\n    <tr>\n      <th>3<\/th>\n      <td>1<\/td>\n      <td>4<\/td>\n      <td>0.0007<\/td>\n      <td>0.0000<\/td>\n      <td>100.0<\/td>\n      <td>518.67<\/td>\n      <td>642.35<\/td>\n      <td>1582.79<\/td>\n      <td>1401.87<\/td>\n      <td>14.62<\/td>\n      <td>...<\/td>\n      <td>522.86<\/td>\n      <td>2388.08<\/td>\n      <td>8133.83<\/td>\n      <td>8.3682<\/td>\n      <td>0.03<\/td>\n      <td>392<\/td>\n      <td>2388<\/td>\n      <td>100.0<\/td>\n      <td>38.88<\/td>\n      <td>23.3739<\/td>\n    <\/tr>\n    <tr>\n      <th>4<\/th>\n      <td>1<\/td>\n      <td>5<\/td>\n      <td>-0.0019<\/td>\n      <td>-0.0002<\/td>\n      <td>100.0<\/td>\n      <td>518.67<\/td>\n      <td>642.37<\/td>\n      <td>1582.85<\/td>\n      <td>1406.22<\/td>\n      <td>14.62<\/td>\n      <td>...<\/td>\n      <td>522.19<\/td>\n      <td>2388.04<\/td>\n      <td>8133.80<\/td>\n      <td>8.4294<\/td>\n      <td>0.03<\/td>\n      <td>393<\/td>\n      <td>2388<\/td>\n      <td>100.0<\/td>\n      <td>38.90<\/td>\n      <td>23.4044<\/td>\n    <\/tr>\n  <\/tbody>\n<\/table>\n<p>5 rows \u00c3\u0097 26 columns<\/p>\n<\/div>"}, "metadata": {}}], "metadata": {"collapsed": false}}, {"source": "## Data Preprocessing\nFirst step is to generate labels for the training data which are Remaining Useful Life (RUL), label1 and label2 as was done in the [Predictive Maintenance Template](https://gallery.cortanaintelligence.com/Collection/Predictive-Maintenance-Template-3). Here, we will only make use of \"label1\" for binary clasification.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 8, "cell_type": "code", "source": "    # generate column RUL\nrul = pd.DataFrame(train_df.groupby('id')['cycle'].max()).reset_index()\nrul.columns = ['id', 'max']\ntrain_df = train_df.merge(rul, on=['id'], how='left')\ntrain_df['RUL'] = train_df['max'] - train_df['cycle']\ntrain_df.drop('max', axis=1, inplace=True)\ntrain_df.head()", "outputs": [{"execution_count": 8, "output_type": "execute_result", "data": {"text/plain": "   id  cycle  setting1  setting2  setting3      s1      s2       s3       s4  \\\n0   1      1   -0.0007   -0.0004     100.0  518.67  641.82  1589.70  1400.60   \n1   1      2    0.0019   -0.0003     100.0  518.67  642.15  1591.82  1403.14   \n2   1      3   -0.0043    0.0003     100.0  518.67  642.35  1587.99  1404.20   \n3   1      4    0.0007    0.0000     100.0  518.67  642.35  1582.79  1401.87   \n4   1      5   -0.0019   -0.0002     100.0  518.67  642.37  1582.85  1406.22   \n\n      s5 ...       s13      s14     s15   s16  s17   s18    s19    s20  \\\n0  14.62 ...   2388.02  8138.62  8.4195  0.03  392  2388  100.0  39.06   \n1  14.62 ...   2388.07  8131.49  8.4318  0.03  392  2388  100.0  39.00   \n2  14.62 ...   2388.03  8133.23  8.4178  0.03  390  2388  100.0  38.95   \n3  14.62 ...   2388.08  8133.83  8.3682  0.03  392  2388  100.0  38.88   \n4  14.62 ...   2388.04  8133.80  8.4294  0.03  393  2388  100.0  38.90   \n\n       s21  RUL  \n0  23.4190  191  \n1  23.4236  190  \n2  23.3442  189  \n3  23.3739  188  \n4  23.4044  187  \n\n[5 rows x 27 columns]", "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th><\/th>\n      <th>id<\/th>\n      <th>cycle<\/th>\n      <th>setting1<\/th>\n      <th>setting2<\/th>\n      <th>setting3<\/th>\n      <th>s1<\/th>\n      <th>s2<\/th>\n      <th>s3<\/th>\n      <th>s4<\/th>\n      <th>s5<\/th>\n      <th>...<\/th>\n      <th>s13<\/th>\n      <th>s14<\/th>\n      <th>s15<\/th>\n      <th>s16<\/th>\n      <th>s17<\/th>\n      <th>s18<\/th>\n      <th>s19<\/th>\n      <th>s20<\/th>\n      <th>s21<\/th>\n      <th>RUL<\/th>\n    <\/tr>\n  <\/thead>\n  <tbody>\n    <tr>\n      <th>0<\/th>\n      <td>1<\/td>\n      <td>1<\/td>\n      <td>-0.0007<\/td>\n      <td>-0.0004<\/td>\n      <td>100.0<\/td>\n      <td>518.67<\/td>\n      <td>641.82<\/td>\n      <td>1589.70<\/td>\n      <td>1400.60<\/td>\n      <td>14.62<\/td>\n      <td>...<\/td>\n      <td>2388.02<\/td>\n      <td>8138.62<\/td>\n      <td>8.4195<\/td>\n      <td>0.03<\/td>\n      <td>392<\/td>\n      <td>2388<\/td>\n      <td>100.0<\/td>\n      <td>39.06<\/td>\n      <td>23.4190<\/td>\n      <td>191<\/td>\n    <\/tr>\n    <tr>\n      <th>1<\/th>\n      <td>1<\/td>\n      <td>2<\/td>\n      <td>0.0019<\/td>\n      <td>-0.0003<\/td>\n      <td>100.0<\/td>\n      <td>518.67<\/td>\n      <td>642.15<\/td>\n      <td>1591.82<\/td>\n      <td>1403.14<\/td>\n      <td>14.62<\/td>\n      <td>...<\/td>\n      <td>2388.07<\/td>\n      <td>8131.49<\/td>\n      <td>8.4318<\/td>\n      <td>0.03<\/td>\n      <td>392<\/td>\n      <td>2388<\/td>\n      <td>100.0<\/td>\n      <td>39.00<\/td>\n      <td>23.4236<\/td>\n      <td>190<\/td>\n    <\/tr>\n    <tr>\n      <th>2<\/th>\n      <td>1<\/td>\n      <td>3<\/td>\n      <td>-0.0043<\/td>\n      <td>0.0003<\/td>\n      <td>100.0<\/td>\n      <td>518.67<\/td>\n      <td>642.35<\/td>\n      <td>1587.99<\/td>\n      <td>1404.20<\/td>\n      <td>14.62<\/td>\n      <td>...<\/td>\n      <td>2388.03<\/td>\n      <td>8133.23<\/td>\n      <td>8.4178<\/td>\n      <td>0.03<\/td>\n      <td>390<\/td>\n      <td>2388<\/td>\n      <td>100.0<\/td>\n      <td>38.95<\/td>\n      <td>23.3442<\/td>\n      <td>189<\/td>\n    <\/tr>\n    <tr>\n      <th>3<\/th>\n      <td>1<\/td>\n      <td>4<\/td>\n      <td>0.0007<\/td>\n      <td>0.0000<\/td>\n      <td>100.0<\/td>\n      <td>518.67<\/td>\n      <td>642.35<\/td>\n      <td>1582.79<\/td>\n      <td>1401.87<\/td>\n      <td>14.62<\/td>\n      <td>...<\/td>\n      <td>2388.08<\/td>\n      <td>8133.83<\/td>\n      <td>8.3682<\/td>\n      <td>0.03<\/td>\n      <td>392<\/td>\n      <td>2388<\/td>\n      <td>100.0<\/td>\n      <td>38.88<\/td>\n      <td>23.3739<\/td>\n      <td>188<\/td>\n    <\/tr>\n    <tr>\n      <th>4<\/th>\n      <td>1<\/td>\n      <td>5<\/td>\n      <td>-0.0019<\/td>\n      <td>-0.0002<\/td>\n      <td>100.0<\/td>\n      <td>518.67<\/td>\n      <td>642.37<\/td>\n      <td>1582.85<\/td>\n      <td>1406.22<\/td>\n      <td>14.62<\/td>\n      <td>...<\/td>\n      <td>2388.04<\/td>\n      <td>8133.80<\/td>\n      <td>8.4294<\/td>\n      <td>0.03<\/td>\n      <td>393<\/td>\n      <td>2388<\/td>\n      <td>100.0<\/td>\n      <td>38.90<\/td>\n      <td>23.4044<\/td>\n      <td>187<\/td>\n    <\/tr>\n  <\/tbody>\n<\/table>\n<p>5 rows \u00c3\u0097 27 columns<\/p>\n<\/div>"}, "metadata": {}}], "metadata": {"collapsed": false}}, {"execution_count": 9, "cell_type": "code", "source": "# generate label columns  for training data\nw1 = 30\nw0 = 15\ntrain_df['label1'] = np.where(train_df['RUL'] <= w1, 1, 0 )\ntrain_df['label2'] = train_df['label1']\ntrain_df.loc[train_df['RUL'] <= w0, 'label2'] = 2\ntrain_df.head()", "outputs": [{"execution_count": 9, "output_type": "execute_result", "data": {"text/plain": "   id  cycle  setting1  setting2  setting3      s1      s2       s3       s4  \\\n0   1      1   -0.0007   -0.0004     100.0  518.67  641.82  1589.70  1400.60   \n1   1      2    0.0019   -0.0003     100.0  518.67  642.15  1591.82  1403.14   \n2   1      3   -0.0043    0.0003     100.0  518.67  642.35  1587.99  1404.20   \n3   1      4    0.0007    0.0000     100.0  518.67  642.35  1582.79  1401.87   \n4   1      5   -0.0019   -0.0002     100.0  518.67  642.37  1582.85  1406.22   \n\n      s5   ...       s15   s16  s17   s18    s19    s20      s21  RUL  label1  \\\n0  14.62   ...    8.4195  0.03  392  2388  100.0  39.06  23.4190  191       0   \n1  14.62   ...    8.4318  0.03  392  2388  100.0  39.00  23.4236  190       0   \n2  14.62   ...    8.4178  0.03  390  2388  100.0  38.95  23.3442  189       0   \n3  14.62   ...    8.3682  0.03  392  2388  100.0  38.88  23.3739  188       0   \n4  14.62   ...    8.4294  0.03  393  2388  100.0  38.90  23.4044  187       0   \n\n   label2  \n0       0  \n1       0  \n2       0  \n3       0  \n4       0  \n\n[5 rows x 29 columns]", "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th><\/th>\n      <th>id<\/th>\n      <th>cycle<\/th>\n      <th>setting1<\/th>\n      <th>setting2<\/th>\n      <th>setting3<\/th>\n      <th>s1<\/th>\n      <th>s2<\/th>\n      <th>s3<\/th>\n      <th>s4<\/th>\n      <th>s5<\/th>\n      <th>...<\/th>\n      <th>s15<\/th>\n      <th>s16<\/th>\n      <th>s17<\/th>\n      <th>s18<\/th>\n      <th>s19<\/th>\n      <th>s20<\/th>\n      <th>s21<\/th>\n      <th>RUL<\/th>\n      <th>label1<\/th>\n      <th>label2<\/th>\n    <\/tr>\n  <\/thead>\n  <tbody>\n    <tr>\n      <th>0<\/th>\n      <td>1<\/td>\n      <td>1<\/td>\n      <td>-0.0007<\/td>\n      <td>-0.0004<\/td>\n      <td>100.0<\/td>\n      <td>518.67<\/td>\n      <td>641.82<\/td>\n      <td>1589.70<\/td>\n      <td>1400.60<\/td>\n      <td>14.62<\/td>\n      <td>...<\/td>\n      <td>8.4195<\/td>\n      <td>0.03<\/td>\n      <td>392<\/td>\n      <td>2388<\/td>\n      <td>100.0<\/td>\n      <td>39.06<\/td>\n      <td>23.4190<\/td>\n      <td>191<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n    <\/tr>\n    <tr>\n      <th>1<\/th>\n      <td>1<\/td>\n      <td>2<\/td>\n      <td>0.0019<\/td>\n      <td>-0.0003<\/td>\n      <td>100.0<\/td>\n      <td>518.67<\/td>\n      <td>642.15<\/td>\n      <td>1591.82<\/td>\n      <td>1403.14<\/td>\n      <td>14.62<\/td>\n      <td>...<\/td>\n      <td>8.4318<\/td>\n      <td>0.03<\/td>\n      <td>392<\/td>\n      <td>2388<\/td>\n      <td>100.0<\/td>\n      <td>39.00<\/td>\n      <td>23.4236<\/td>\n      <td>190<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n    <\/tr>\n    <tr>\n      <th>2<\/th>\n      <td>1<\/td>\n      <td>3<\/td>\n      <td>-0.0043<\/td>\n      <td>0.0003<\/td>\n      <td>100.0<\/td>\n      <td>518.67<\/td>\n      <td>642.35<\/td>\n      <td>1587.99<\/td>\n      <td>1404.20<\/td>\n      <td>14.62<\/td>\n      <td>...<\/td>\n      <td>8.4178<\/td>\n      <td>0.03<\/td>\n      <td>390<\/td>\n      <td>2388<\/td>\n      <td>100.0<\/td>\n      <td>38.95<\/td>\n      <td>23.3442<\/td>\n      <td>189<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n    <\/tr>\n    <tr>\n      <th>3<\/th>\n      <td>1<\/td>\n      <td>4<\/td>\n      <td>0.0007<\/td>\n      <td>0.0000<\/td>\n      <td>100.0<\/td>\n      <td>518.67<\/td>\n      <td>642.35<\/td>\n      <td>1582.79<\/td>\n      <td>1401.87<\/td>\n      <td>14.62<\/td>\n      <td>...<\/td>\n      <td>8.3682<\/td>\n      <td>0.03<\/td>\n      <td>392<\/td>\n      <td>2388<\/td>\n      <td>100.0<\/td>\n      <td>38.88<\/td>\n      <td>23.3739<\/td>\n      <td>188<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n    <\/tr>\n    <tr>\n      <th>4<\/th>\n      <td>1<\/td>\n      <td>5<\/td>\n      <td>-0.0019<\/td>\n      <td>-0.0002<\/td>\n      <td>100.0<\/td>\n      <td>518.67<\/td>\n      <td>642.37<\/td>\n      <td>1582.85<\/td>\n      <td>1406.22<\/td>\n      <td>14.62<\/td>\n      <td>...<\/td>\n      <td>8.4294<\/td>\n      <td>0.03<\/td>\n      <td>393<\/td>\n      <td>2388<\/td>\n      <td>100.0<\/td>\n      <td>38.90<\/td>\n      <td>23.4044<\/td>\n      <td>187<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n    <\/tr>\n  <\/tbody>\n<\/table>\n<p>5 rows \u00c3\u0097 29 columns<\/p>\n<\/div>"}, "metadata": {}}], "metadata": {"scrolled": false, "collapsed": false}}, {"source": "In the [Predictive Maintenance Template](https://gallery.cortanaintelligence.com/Collection/Predictive-Maintenance-Template-3) , cycle column is also used for training so we will also include the cycle column. Here, we normalize the columns in the training data.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 10, "cell_type": "code", "source": "# MinMax normalization\ntrain_df['cycle_norm'] = train_df['cycle']\ncols_normalize = train_df.columns.difference(['id','cycle','RUL','label1','label2'])\nmin_max_scaler = preprocessing.MinMaxScaler()\nnorm_train_df = pd.DataFrame(min_max_scaler.fit_transform(train_df[cols_normalize]), \n                             columns=cols_normalize, \n                             index=train_df.index)\njoin_df = train_df[train_df.columns.difference(cols_normalize)].join(norm_train_df)\ntrain_df = join_df.reindex(columns = train_df.columns)\ntrain_df.head()", "outputs": [{"execution_count": 10, "output_type": "execute_result", "data": {"text/plain": "   id  cycle  setting1  setting2  setting3   s1        s2        s3        s4  \\\n0   1      1  0.459770  0.166667       0.0  0.0  0.183735  0.406802  0.309757   \n1   1      2  0.609195  0.250000       0.0  0.0  0.283133  0.453019  0.352633   \n2   1      3  0.252874  0.750000       0.0  0.0  0.343373  0.369523  0.370527   \n3   1      4  0.540230  0.500000       0.0  0.0  0.343373  0.256159  0.331195   \n4   1      5  0.390805  0.333333       0.0  0.0  0.349398  0.257467  0.404625   \n\n    s5     ...      s16       s17  s18  s19       s20       s21  RUL  label1  \\\n0  0.0     ...      0.0  0.333333  0.0  0.0  0.713178  0.724662  191       0   \n1  0.0     ...      0.0  0.333333  0.0  0.0  0.666667  0.731014  190       0   \n2  0.0     ...      0.0  0.166667  0.0  0.0  0.627907  0.621375  189       0   \n3  0.0     ...      0.0  0.333333  0.0  0.0  0.573643  0.662386  188       0   \n4  0.0     ...      0.0  0.416667  0.0  0.0  0.589147  0.704502  187       0   \n\n   label2  cycle_norm  \n0       0     0.00000  \n1       0     0.00277  \n2       0     0.00554  \n3       0     0.00831  \n4       0     0.01108  \n\n[5 rows x 30 columns]", "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th><\/th>\n      <th>id<\/th>\n      <th>cycle<\/th>\n      <th>setting1<\/th>\n      <th>setting2<\/th>\n      <th>setting3<\/th>\n      <th>s1<\/th>\n      <th>s2<\/th>\n      <th>s3<\/th>\n      <th>s4<\/th>\n      <th>s5<\/th>\n      <th>...<\/th>\n      <th>s16<\/th>\n      <th>s17<\/th>\n      <th>s18<\/th>\n      <th>s19<\/th>\n      <th>s20<\/th>\n      <th>s21<\/th>\n      <th>RUL<\/th>\n      <th>label1<\/th>\n      <th>label2<\/th>\n      <th>cycle_norm<\/th>\n    <\/tr>\n  <\/thead>\n  <tbody>\n    <tr>\n      <th>0<\/th>\n      <td>1<\/td>\n      <td>1<\/td>\n      <td>0.459770<\/td>\n      <td>0.166667<\/td>\n      <td>0.0<\/td>\n      <td>0.0<\/td>\n      <td>0.183735<\/td>\n      <td>0.406802<\/td>\n      <td>0.309757<\/td>\n      <td>0.0<\/td>\n      <td>...<\/td>\n      <td>0.0<\/td>\n      <td>0.333333<\/td>\n      <td>0.0<\/td>\n      <td>0.0<\/td>\n      <td>0.713178<\/td>\n      <td>0.724662<\/td>\n      <td>191<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>0.00000<\/td>\n    <\/tr>\n    <tr>\n      <th>1<\/th>\n      <td>1<\/td>\n      <td>2<\/td>\n      <td>0.609195<\/td>\n      <td>0.250000<\/td>\n      <td>0.0<\/td>\n      <td>0.0<\/td>\n      <td>0.283133<\/td>\n      <td>0.453019<\/td>\n      <td>0.352633<\/td>\n      <td>0.0<\/td>\n      <td>...<\/td>\n      <td>0.0<\/td>\n      <td>0.333333<\/td>\n      <td>0.0<\/td>\n      <td>0.0<\/td>\n      <td>0.666667<\/td>\n      <td>0.731014<\/td>\n      <td>190<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>0.00277<\/td>\n    <\/tr>\n    <tr>\n      <th>2<\/th>\n      <td>1<\/td>\n      <td>3<\/td>\n      <td>0.252874<\/td>\n      <td>0.750000<\/td>\n      <td>0.0<\/td>\n      <td>0.0<\/td>\n      <td>0.343373<\/td>\n      <td>0.369523<\/td>\n      <td>0.370527<\/td>\n      <td>0.0<\/td>\n      <td>...<\/td>\n      <td>0.0<\/td>\n      <td>0.166667<\/td>\n      <td>0.0<\/td>\n      <td>0.0<\/td>\n      <td>0.627907<\/td>\n      <td>0.621375<\/td>\n      <td>189<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>0.00554<\/td>\n    <\/tr>\n    <tr>\n      <th>3<\/th>\n      <td>1<\/td>\n      <td>4<\/td>\n      <td>0.540230<\/td>\n      <td>0.500000<\/td>\n      <td>0.0<\/td>\n      <td>0.0<\/td>\n      <td>0.343373<\/td>\n      <td>0.256159<\/td>\n      <td>0.331195<\/td>\n      <td>0.0<\/td>\n      <td>...<\/td>\n      <td>0.0<\/td>\n      <td>0.333333<\/td>\n      <td>0.0<\/td>\n      <td>0.0<\/td>\n      <td>0.573643<\/td>\n      <td>0.662386<\/td>\n      <td>188<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>0.00831<\/td>\n    <\/tr>\n    <tr>\n      <th>4<\/th>\n      <td>1<\/td>\n      <td>5<\/td>\n      <td>0.390805<\/td>\n      <td>0.333333<\/td>\n      <td>0.0<\/td>\n      <td>0.0<\/td>\n      <td>0.349398<\/td>\n      <td>0.257467<\/td>\n      <td>0.404625<\/td>\n      <td>0.0<\/td>\n      <td>...<\/td>\n      <td>0.0<\/td>\n      <td>0.416667<\/td>\n      <td>0.0<\/td>\n      <td>0.0<\/td>\n      <td>0.589147<\/td>\n      <td>0.704502<\/td>\n      <td>187<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>0.01108<\/td>\n    <\/tr>\n  <\/tbody>\n<\/table>\n<p>5 rows \u00c3\u0097 30 columns<\/p>\n<\/div>"}, "metadata": {}}], "metadata": {"scrolled": true, "collapsed": false}}, {"execution_count": 124, "cell_type": "code", "source": "# Sensor plot visual for Train Data (s2)\nplt.scatter(train_df['cycle'],train_df['s2'], color='red')\nplt.xlim(0,100)\nplt.title(\"Sensor Values - Train Data\")\nplt.xlabel(\"Cycle\")\nplt.ylabel(\"s2 Values\")", "outputs": [{"execution_count": 124, "output_type": "execute_result", "data": {"text/plain": "<matplotlib.text.Text at 0x7f4639e09d30>"}, "metadata": {}}, {"output_type": "display_data", "data": {"image/png": "iVBORw0KGgoAAAANSUhEUgAAAZYAAAEZCAYAAAC0HgObAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n", "text/plain": "<matplotlib.figure.Figure at 0x7f463a2d3128>"}, "metadata": {}}], "metadata": {"scrolled": false, "collapsed": false}}, {"execution_count": 125, "cell_type": "code", "source": "# Sensor plot visual for Train Data (s3)\nplt.scatter(train_df['cycle'],train_df['s3'], color='blue')\nplt.xlim(0,100)\nplt.title(\"Sensor Values - Train Data\")\nplt.xlabel(\"Cycle\")\nplt.ylabel(\"s3 Values\")", "outputs": [{"execution_count": 125, "output_type": "execute_result", "data": {"text/plain": "<matplotlib.text.Text at 0x7f4639d73780>"}, "metadata": {}}, {"output_type": "display_data", "data": {"image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEZCAYAAABSN8jfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n", "text/plain": "<matplotlib.figure.Figure at 0x7f4639e22cf8>"}, "metadata": {}}], "metadata": {"collapsed": false}}, {"source": "Next, we prepare the test data. We first normalize the test data using the parameters from the MinMax normalization applied on the training data. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": 11, "cell_type": "code", "source": "test_df['cycle_norm'] = test_df['cycle']\nnorm_test_df = pd.DataFrame(min_max_scaler.transform(test_df[cols_normalize]), \n                            columns=cols_normalize, \n                            index=test_df.index)\ntest_join_df = test_df[test_df.columns.difference(cols_normalize)].join(norm_test_df)\ntest_df = test_join_df.reindex(columns = test_df.columns)\ntest_df = test_df.reset_index(drop=True)\ntest_df.head()", "outputs": [{"execution_count": 11, "output_type": "execute_result", "data": {"text/plain": "   id  cycle  setting1  setting2  setting3   s1        s2        s3        s4  \\\n0   1      1  0.632184  0.750000       0.0  0.0  0.545181  0.310661  0.269413   \n1   1      2  0.344828  0.250000       0.0  0.0  0.150602  0.379551  0.222316   \n2   1      3  0.517241  0.583333       0.0  0.0  0.376506  0.346632  0.322248   \n3   1      4  0.741379  0.500000       0.0  0.0  0.370482  0.285154  0.408001   \n4   1      5  0.580460  0.500000       0.0  0.0  0.391566  0.352082  0.332039   \n\n    s5     ...           s13       s14       s15  s16       s17  s18  s19  \\\n0  0.0     ...      0.220588  0.132160  0.308965  0.0  0.333333  0.0  0.0   \n1  0.0     ...      0.264706  0.204768  0.213159  0.0  0.416667  0.0  0.0   \n2  0.0     ...      0.220588  0.155640  0.458638  0.0  0.416667  0.0  0.0   \n3  0.0     ...      0.250000  0.170090  0.257022  0.0  0.250000  0.0  0.0   \n4  0.0     ...      0.220588  0.152751  0.300885  0.0  0.166667  0.0  0.0   \n\n        s20       s21  cycle_norm  \n0  0.558140  0.661834     0.00000  \n1  0.682171  0.686827     0.00277  \n2  0.728682  0.721348     0.00554  \n3  0.666667  0.662110     0.00831  \n4  0.658915  0.716377     0.01108  \n\n[5 rows x 27 columns]", "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th><\/th>\n      <th>id<\/th>\n      <th>cycle<\/th>\n      <th>setting1<\/th>\n      <th>setting2<\/th>\n      <th>setting3<\/th>\n      <th>s1<\/th>\n      <th>s2<\/th>\n      <th>s3<\/th>\n      <th>s4<\/th>\n      <th>s5<\/th>\n      <th>...<\/th>\n      <th>s13<\/th>\n      <th>s14<\/th>\n      <th>s15<\/th>\n      <th>s16<\/th>\n      <th>s17<\/th>\n      <th>s18<\/th>\n      <th>s19<\/th>\n      <th>s20<\/th>\n      <th>s21<\/th>\n      <th>cycle_norm<\/th>\n    <\/tr>\n  <\/thead>\n  <tbody>\n    <tr>\n      <th>0<\/th>\n      <td>1<\/td>\n      <td>1<\/td>\n      <td>0.632184<\/td>\n      <td>0.750000<\/td>\n      <td>0.0<\/td>\n      <td>0.0<\/td>\n      <td>0.545181<\/td>\n      <td>0.310661<\/td>\n      <td>0.269413<\/td>\n      <td>0.0<\/td>\n      <td>...<\/td>\n      <td>0.220588<\/td>\n      <td>0.132160<\/td>\n      <td>0.308965<\/td>\n      <td>0.0<\/td>\n      <td>0.333333<\/td>\n      <td>0.0<\/td>\n      <td>0.0<\/td>\n      <td>0.558140<\/td>\n      <td>0.661834<\/td>\n      <td>0.00000<\/td>\n    <\/tr>\n    <tr>\n      <th>1<\/th>\n      <td>1<\/td>\n      <td>2<\/td>\n      <td>0.344828<\/td>\n      <td>0.250000<\/td>\n      <td>0.0<\/td>\n      <td>0.0<\/td>\n      <td>0.150602<\/td>\n      <td>0.379551<\/td>\n      <td>0.222316<\/td>\n      <td>0.0<\/td>\n      <td>...<\/td>\n      <td>0.264706<\/td>\n      <td>0.204768<\/td>\n      <td>0.213159<\/td>\n      <td>0.0<\/td>\n      <td>0.416667<\/td>\n      <td>0.0<\/td>\n      <td>0.0<\/td>\n      <td>0.682171<\/td>\n      <td>0.686827<\/td>\n      <td>0.00277<\/td>\n    <\/tr>\n    <tr>\n      <th>2<\/th>\n      <td>1<\/td>\n      <td>3<\/td>\n      <td>0.517241<\/td>\n      <td>0.583333<\/td>\n      <td>0.0<\/td>\n      <td>0.0<\/td>\n      <td>0.376506<\/td>\n      <td>0.346632<\/td>\n      <td>0.322248<\/td>\n      <td>0.0<\/td>\n      <td>...<\/td>\n      <td>0.220588<\/td>\n      <td>0.155640<\/td>\n      <td>0.458638<\/td>\n      <td>0.0<\/td>\n      <td>0.416667<\/td>\n      <td>0.0<\/td>\n      <td>0.0<\/td>\n      <td>0.728682<\/td>\n      <td>0.721348<\/td>\n      <td>0.00554<\/td>\n    <\/tr>\n    <tr>\n      <th>3<\/th>\n      <td>1<\/td>\n      <td>4<\/td>\n      <td>0.741379<\/td>\n      <td>0.500000<\/td>\n      <td>0.0<\/td>\n      <td>0.0<\/td>\n      <td>0.370482<\/td>\n      <td>0.285154<\/td>\n      <td>0.408001<\/td>\n      <td>0.0<\/td>\n      <td>...<\/td>\n      <td>0.250000<\/td>\n      <td>0.170090<\/td>\n      <td>0.257022<\/td>\n      <td>0.0<\/td>\n      <td>0.250000<\/td>\n      <td>0.0<\/td>\n      <td>0.0<\/td>\n      <td>0.666667<\/td>\n      <td>0.662110<\/td>\n      <td>0.00831<\/td>\n    <\/tr>\n    <tr>\n      <th>4<\/th>\n      <td>1<\/td>\n      <td>5<\/td>\n      <td>0.580460<\/td>\n      <td>0.500000<\/td>\n      <td>0.0<\/td>\n      <td>0.0<\/td>\n      <td>0.391566<\/td>\n      <td>0.352082<\/td>\n      <td>0.332039<\/td>\n      <td>0.0<\/td>\n      <td>...<\/td>\n      <td>0.220588<\/td>\n      <td>0.152751<\/td>\n      <td>0.300885<\/td>\n      <td>0.0<\/td>\n      <td>0.166667<\/td>\n      <td>0.0<\/td>\n      <td>0.0<\/td>\n      <td>0.658915<\/td>\n      <td>0.716377<\/td>\n      <td>0.01108<\/td>\n    <\/tr>\n  <\/tbody>\n<\/table>\n<p>5 rows \u00c3\u0097 27 columns<\/p>\n<\/div>"}, "metadata": {}}], "metadata": {"collapsed": false}}, {"source": "Next, we use the ground truth dataset to generate labels for the test data.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 12, "cell_type": "code", "source": "# generate column max for test data\nrul = pd.DataFrame(test_df.groupby('id')['cycle'].max()).reset_index()\nrul.columns = ['id', 'max']\ntruth_df.columns = ['more']\ntruth_df['id'] = truth_df.index + 1\ntruth_df['max'] = rul['max'] + truth_df['more']\ntruth_df.drop('more', axis=1, inplace=True)", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 13, "cell_type": "code", "source": "# generate RUL for test data\ntest_df = test_df.merge(truth_df, on=['id'], how='left')\ntest_df['RUL'] = test_df['max'] - test_df['cycle']\ntest_df.drop('max', axis=1, inplace=True)\ntest_df.head()", "outputs": [{"execution_count": 13, "output_type": "execute_result", "data": {"text/plain": "   id  cycle  setting1  setting2  setting3   s1        s2        s3        s4  \\\n0   1      1  0.632184  0.750000       0.0  0.0  0.545181  0.310661  0.269413   \n1   1      2  0.344828  0.250000       0.0  0.0  0.150602  0.379551  0.222316   \n2   1      3  0.517241  0.583333       0.0  0.0  0.376506  0.346632  0.322248   \n3   1      4  0.741379  0.500000       0.0  0.0  0.370482  0.285154  0.408001   \n4   1      5  0.580460  0.500000       0.0  0.0  0.391566  0.352082  0.332039   \n\n    s5 ...        s14       s15  s16       s17  s18  s19       s20       s21  \\\n0  0.0 ...   0.132160  0.308965  0.0  0.333333  0.0  0.0  0.558140  0.661834   \n1  0.0 ...   0.204768  0.213159  0.0  0.416667  0.0  0.0  0.682171  0.686827   \n2  0.0 ...   0.155640  0.458638  0.0  0.416667  0.0  0.0  0.728682  0.721348   \n3  0.0 ...   0.170090  0.257022  0.0  0.250000  0.0  0.0  0.666667  0.662110   \n4  0.0 ...   0.152751  0.300885  0.0  0.166667  0.0  0.0  0.658915  0.716377   \n\n   cycle_norm  RUL  \n0     0.00000  142  \n1     0.00277  141  \n2     0.00554  140  \n3     0.00831  139  \n4     0.01108  138  \n\n[5 rows x 28 columns]", "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th><\/th>\n      <th>id<\/th>\n      <th>cycle<\/th>\n      <th>setting1<\/th>\n      <th>setting2<\/th>\n      <th>setting3<\/th>\n      <th>s1<\/th>\n      <th>s2<\/th>\n      <th>s3<\/th>\n      <th>s4<\/th>\n      <th>s5<\/th>\n      <th>...<\/th>\n      <th>s14<\/th>\n      <th>s15<\/th>\n      <th>s16<\/th>\n      <th>s17<\/th>\n      <th>s18<\/th>\n      <th>s19<\/th>\n      <th>s20<\/th>\n      <th>s21<\/th>\n      <th>cycle_norm<\/th>\n      <th>RUL<\/th>\n    <\/tr>\n  <\/thead>\n  <tbody>\n    <tr>\n      <th>0<\/th>\n      <td>1<\/td>\n      <td>1<\/td>\n      <td>0.632184<\/td>\n      <td>0.750000<\/td>\n      <td>0.0<\/td>\n      <td>0.0<\/td>\n      <td>0.545181<\/td>\n      <td>0.310661<\/td>\n      <td>0.269413<\/td>\n      <td>0.0<\/td>\n      <td>...<\/td>\n      <td>0.132160<\/td>\n      <td>0.308965<\/td>\n      <td>0.0<\/td>\n      <td>0.333333<\/td>\n      <td>0.0<\/td>\n      <td>0.0<\/td>\n      <td>0.558140<\/td>\n      <td>0.661834<\/td>\n      <td>0.00000<\/td>\n      <td>142<\/td>\n    <\/tr>\n    <tr>\n      <th>1<\/th>\n      <td>1<\/td>\n      <td>2<\/td>\n      <td>0.344828<\/td>\n      <td>0.250000<\/td>\n      <td>0.0<\/td>\n      <td>0.0<\/td>\n      <td>0.150602<\/td>\n      <td>0.379551<\/td>\n      <td>0.222316<\/td>\n      <td>0.0<\/td>\n      <td>...<\/td>\n      <td>0.204768<\/td>\n      <td>0.213159<\/td>\n      <td>0.0<\/td>\n      <td>0.416667<\/td>\n      <td>0.0<\/td>\n      <td>0.0<\/td>\n      <td>0.682171<\/td>\n      <td>0.686827<\/td>\n      <td>0.00277<\/td>\n      <td>141<\/td>\n    <\/tr>\n    <tr>\n      <th>2<\/th>\n      <td>1<\/td>\n      <td>3<\/td>\n      <td>0.517241<\/td>\n      <td>0.583333<\/td>\n      <td>0.0<\/td>\n      <td>0.0<\/td>\n      <td>0.376506<\/td>\n      <td>0.346632<\/td>\n      <td>0.322248<\/td>\n      <td>0.0<\/td>\n      <td>...<\/td>\n      <td>0.155640<\/td>\n      <td>0.458638<\/td>\n      <td>0.0<\/td>\n      <td>0.416667<\/td>\n      <td>0.0<\/td>\n      <td>0.0<\/td>\n      <td>0.728682<\/td>\n      <td>0.721348<\/td>\n      <td>0.00554<\/td>\n      <td>140<\/td>\n    <\/tr>\n    <tr>\n      <th>3<\/th>\n      <td>1<\/td>\n      <td>4<\/td>\n      <td>0.741379<\/td>\n      <td>0.500000<\/td>\n      <td>0.0<\/td>\n      <td>0.0<\/td>\n      <td>0.370482<\/td>\n      <td>0.285154<\/td>\n      <td>0.408001<\/td>\n      <td>0.0<\/td>\n      <td>...<\/td>\n      <td>0.170090<\/td>\n      <td>0.257022<\/td>\n      <td>0.0<\/td>\n      <td>0.250000<\/td>\n      <td>0.0<\/td>\n      <td>0.0<\/td>\n      <td>0.666667<\/td>\n      <td>0.662110<\/td>\n      <td>0.00831<\/td>\n      <td>139<\/td>\n    <\/tr>\n    <tr>\n      <th>4<\/th>\n      <td>1<\/td>\n      <td>5<\/td>\n      <td>0.580460<\/td>\n      <td>0.500000<\/td>\n      <td>0.0<\/td>\n      <td>0.0<\/td>\n      <td>0.391566<\/td>\n      <td>0.352082<\/td>\n      <td>0.332039<\/td>\n      <td>0.0<\/td>\n      <td>...<\/td>\n      <td>0.152751<\/td>\n      <td>0.300885<\/td>\n      <td>0.0<\/td>\n      <td>0.166667<\/td>\n      <td>0.0<\/td>\n      <td>0.0<\/td>\n      <td>0.658915<\/td>\n      <td>0.716377<\/td>\n      <td>0.01108<\/td>\n      <td>138<\/td>\n    <\/tr>\n  <\/tbody>\n<\/table>\n<p>5 rows \u00c3\u0097 28 columns<\/p>\n<\/div>"}, "metadata": {}}], "metadata": {"collapsed": false}}, {"execution_count": 14, "cell_type": "code", "source": "# generate label columns w0 and w1 for test data\ntest_df['label1'] = np.where(test_df['RUL'] <= w1, 1, 0 )\ntest_df['label2'] = test_df['label1']\ntest_df.loc[test_df['RUL'] <= w0, 'label2'] = 2\ntest_df.head()", "outputs": [{"execution_count": 14, "output_type": "execute_result", "data": {"text/plain": "   id  cycle  setting1  setting2  setting3   s1        s2        s3        s4  \\\n0   1      1  0.632184  0.750000       0.0  0.0  0.545181  0.310661  0.269413   \n1   1      2  0.344828  0.250000       0.0  0.0  0.150602  0.379551  0.222316   \n2   1      3  0.517241  0.583333       0.0  0.0  0.376506  0.346632  0.322248   \n3   1      4  0.741379  0.500000       0.0  0.0  0.370482  0.285154  0.408001   \n4   1      5  0.580460  0.500000       0.0  0.0  0.391566  0.352082  0.332039   \n\n    s5   ...    s16       s17  s18  s19       s20       s21  cycle_norm  RUL  \\\n0  0.0   ...    0.0  0.333333  0.0  0.0  0.558140  0.661834     0.00000  142   \n1  0.0   ...    0.0  0.416667  0.0  0.0  0.682171  0.686827     0.00277  141   \n2  0.0   ...    0.0  0.416667  0.0  0.0  0.728682  0.721348     0.00554  140   \n3  0.0   ...    0.0  0.250000  0.0  0.0  0.666667  0.662110     0.00831  139   \n4  0.0   ...    0.0  0.166667  0.0  0.0  0.658915  0.716377     0.01108  138   \n\n   label1  label2  \n0       0       0  \n1       0       0  \n2       0       0  \n3       0       0  \n4       0       0  \n\n[5 rows x 30 columns]", "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th><\/th>\n      <th>id<\/th>\n      <th>cycle<\/th>\n      <th>setting1<\/th>\n      <th>setting2<\/th>\n      <th>setting3<\/th>\n      <th>s1<\/th>\n      <th>s2<\/th>\n      <th>s3<\/th>\n      <th>s4<\/th>\n      <th>s5<\/th>\n      <th>...<\/th>\n      <th>s16<\/th>\n      <th>s17<\/th>\n      <th>s18<\/th>\n      <th>s19<\/th>\n      <th>s20<\/th>\n      <th>s21<\/th>\n      <th>cycle_norm<\/th>\n      <th>RUL<\/th>\n      <th>label1<\/th>\n      <th>label2<\/th>\n    <\/tr>\n  <\/thead>\n  <tbody>\n    <tr>\n      <th>0<\/th>\n      <td>1<\/td>\n      <td>1<\/td>\n      <td>0.632184<\/td>\n      <td>0.750000<\/td>\n      <td>0.0<\/td>\n      <td>0.0<\/td>\n      <td>0.545181<\/td>\n      <td>0.310661<\/td>\n      <td>0.269413<\/td>\n      <td>0.0<\/td>\n      <td>...<\/td>\n      <td>0.0<\/td>\n      <td>0.333333<\/td>\n      <td>0.0<\/td>\n      <td>0.0<\/td>\n      <td>0.558140<\/td>\n      <td>0.661834<\/td>\n      <td>0.00000<\/td>\n      <td>142<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n    <\/tr>\n    <tr>\n      <th>1<\/th>\n      <td>1<\/td>\n      <td>2<\/td>\n      <td>0.344828<\/td>\n      <td>0.250000<\/td>\n      <td>0.0<\/td>\n      <td>0.0<\/td>\n      <td>0.150602<\/td>\n      <td>0.379551<\/td>\n      <td>0.222316<\/td>\n      <td>0.0<\/td>\n      <td>...<\/td>\n      <td>0.0<\/td>\n      <td>0.416667<\/td>\n      <td>0.0<\/td>\n      <td>0.0<\/td>\n      <td>0.682171<\/td>\n      <td>0.686827<\/td>\n      <td>0.00277<\/td>\n      <td>141<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n    <\/tr>\n    <tr>\n      <th>2<\/th>\n      <td>1<\/td>\n      <td>3<\/td>\n      <td>0.517241<\/td>\n      <td>0.583333<\/td>\n      <td>0.0<\/td>\n      <td>0.0<\/td>\n      <td>0.376506<\/td>\n      <td>0.346632<\/td>\n      <td>0.322248<\/td>\n      <td>0.0<\/td>\n      <td>...<\/td>\n      <td>0.0<\/td>\n      <td>0.416667<\/td>\n      <td>0.0<\/td>\n      <td>0.0<\/td>\n      <td>0.728682<\/td>\n      <td>0.721348<\/td>\n      <td>0.00554<\/td>\n      <td>140<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n    <\/tr>\n    <tr>\n      <th>3<\/th>\n      <td>1<\/td>\n      <td>4<\/td>\n      <td>0.741379<\/td>\n      <td>0.500000<\/td>\n      <td>0.0<\/td>\n      <td>0.0<\/td>\n      <td>0.370482<\/td>\n      <td>0.285154<\/td>\n      <td>0.408001<\/td>\n      <td>0.0<\/td>\n      <td>...<\/td>\n      <td>0.0<\/td>\n      <td>0.250000<\/td>\n      <td>0.0<\/td>\n      <td>0.0<\/td>\n      <td>0.666667<\/td>\n      <td>0.662110<\/td>\n      <td>0.00831<\/td>\n      <td>139<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n    <\/tr>\n    <tr>\n      <th>4<\/th>\n      <td>1<\/td>\n      <td>5<\/td>\n      <td>0.580460<\/td>\n      <td>0.500000<\/td>\n      <td>0.0<\/td>\n      <td>0.0<\/td>\n      <td>0.391566<\/td>\n      <td>0.352082<\/td>\n      <td>0.332039<\/td>\n      <td>0.0<\/td>\n      <td>...<\/td>\n      <td>0.0<\/td>\n      <td>0.166667<\/td>\n      <td>0.0<\/td>\n      <td>0.0<\/td>\n      <td>0.658915<\/td>\n      <td>0.716377<\/td>\n      <td>0.01108<\/td>\n      <td>138<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n    <\/tr>\n  <\/tbody>\n<\/table>\n<p>5 rows \u00c3\u0097 30 columns<\/p>\n<\/div>"}, "metadata": {}}], "metadata": {"collapsed": false}}, {"source": "In the rest of the notebook, we train an LSTM network that we will compare to the results in [Predictive Maintenance Template Step 2B of 3](https://gallery.cortanaintelligence.com/Experiment/Predictive-Maintenance-Step-2B-of-3-train-and-evaluate-binary-classification-models-2) where a series of machine learning models are used to train and evaluate the binary classification model that uses column \"label1\" as the label.", "cell_type": "markdown", "metadata": {}}, {"source": "## Modelling\n\nThe traditional predictive maintenance machine learning models are based on feature engineering which is manual construction of right features using domain expertise and similar methods. This usually makes these models hard to reuse since feature engineering is specific to the problem scenario and the available data which varies from one business to the other. Perhaps the most attractive part of applying deep learning in the predictive maintenance domain is the fact that these networks can automatically extract the right features from the data, eliminating the need for manual feature engineering.\n\nWhen using LSTMs in the time-series domain, one important parameter to pick is the sequence length which is the window for LSTMs to look back. This may be viewed as similar to picking window_size = 5 cycles for calculating the rolling features in the [Predictive Maintenance Template](https://gallery.cortanaintelligence.com/Collection/Predictive-Maintenance-Template-3) which are rolling mean and rolling standard deviation for 21 sensor values. The idea of using LSTMs is to let the model extract abstract features out of the sequence of sensor values in the window rather than engineering those manually. The expectation is that if there is a pattern in these sensor values within the window prior to failure, the pattern should be encoded by the LSTM.\n\nOne critical advantage of LSTMs is their ability to remember from long-term sequences (window sizes) which is hard to achieve by traditional feature engineering. For example, computing rolling averages over a window size of 50 cycles may lead to loss of information due to smoothing and abstracting of values over such a long period, istead, using all 50 values as input may provide better results. While feature engineering over large window sizes may not make sense, LSTMs are able to use larger window sizes and use all the information in the window as input. Below, we illustrate the approach.\n", "cell_type": "markdown", "metadata": {}}, {"execution_count": 15, "cell_type": "code", "source": "# pick a large window size of 50 cycles\nsequence_length = 50", "outputs": [], "metadata": {"collapsed": true}}, {"source": "[Keras LSTM](https://keras.io/layers/recurrent/) layers expect an input in the shape of a numpy array of 3 dimensions (samples, time steps, features) where samples is the number of training sequences, time steps is the look back window or sequence length and features is the number of features of each sequence at each time step. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": 16, "cell_type": "code", "source": "# function to reshape features into (samples, time steps, features) \ndef gen_sequence(id_df, seq_length, seq_cols):\n    \"\"\" Only sequences that meet the window-length are considered, no padding is used. This means for testing\n    we need to drop those which are below the window-length. An alternative would be to pad sequences so that\n    we can use shorter ones \"\"\"\n    data_array = id_df[seq_cols].values\n    num_elements = data_array.shape[0]\n    for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n        yield data_array[start:stop, :]", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 17, "cell_type": "code", "source": "# pick the feature columns \nsensor_cols = ['s' + str(i) for i in range(1,22)]\nsequence_cols = ['setting1', 'setting2', 'setting3', 'cycle_norm']\nsequence_cols.extend(sensor_cols)", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 18, "cell_type": "code", "source": "# generator for the sequences\nseq_gen = (list(gen_sequence(train_df[train_df['id']==id], sequence_length, sequence_cols)) \n           for id in train_df['id'].unique())", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 19, "cell_type": "code", "source": "# generate sequences and convert to numpy array\nseq_array = np.concatenate(list(seq_gen))\nseq_array.shape", "outputs": [{"execution_count": 19, "output_type": "execute_result", "data": {"text/plain": "(15631, 50, 25)"}, "metadata": {}}], "metadata": {"collapsed": false}}, {"execution_count": 20, "cell_type": "code", "source": "# function to generate labels\ndef gen_labels(id_df, seq_length, label):\n    data_array = id_df[label].values\n    num_elements = data_array.shape[0]\n    return data_array[seq_length:num_elements, :]", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 21, "cell_type": "code", "source": "# generate labels\nlabel_gen = [gen_labels(train_df[train_df['id']==id], sequence_length, ['label1']) \n             for id in train_df['id'].unique()]\nlabel_array = np.concatenate(label_gen)\nlabel_array.shape", "outputs": [{"execution_count": 21, "output_type": "execute_result", "data": {"text/plain": "(15631, 1)"}, "metadata": {}}], "metadata": {"collapsed": false}}, {"source": "## LSTM Network\nNext, we build a deep network. The first layer is an LSTM layer with 100 units followed by another LSTM layer with 50 units. Dropout is also applied after each LSTM layer to control overfitting. Final layer is a Dense output layer with single unit and sigmoid activation since this is a binary classification problem.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 22, "cell_type": "code", "source": "# build the network\nnb_features = seq_array.shape[2]\nnb_out = label_array.shape[1]\n\nmodel = Sequential()\n\nmodel.add(LSTM(\n         input_shape=(sequence_length, nb_features),\n         units=100,\n         return_sequences=True))\nmodel.add(Dropout(0.2))\n\nmodel.add(LSTM(\n          units=50,\n          return_sequences=False))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(units=nb_out, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 23, "cell_type": "code", "source": "# fit the network\nmodel.fit(seq_array, label_array, epochs=3, batch_size = 200, validation_split=0.05, verbose=2)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Train on 14849 samples, validate on 782 samples\nEpoch 1/3\n20s - loss: 0.2529 - acc: 0.8923 - val_loss: 0.0961 - val_acc: 0.9604\nEpoch 2/3\n19s - loss: 0.0891 - acc: 0.9621 - val_loss: 0.0535 - val_acc: 0.9770\nEpoch 3/3\n20s - loss: 0.0834 - acc: 0.9640 - val_loss: 0.0542 - val_acc: 0.9693\n"}, {"execution_count": 23, "output_type": "execute_result", "data": {"text/plain": "<keras.callbacks.History at 0x7f46c99f1fd0>"}, "metadata": {}}], "metadata": {"collapsed": false}}, {"execution_count": 24, "cell_type": "code", "source": "print(model.summary())", "outputs": [{"output_type": "stream", "name": "stdout", "text": "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nlstm_1 (LSTM)                (None, 50, 100)           50400     \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 50, 100)           0         \n_________________________________________________________________\nlstm_2 (LSTM)                (None, 50)                30200     \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 50)                0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 51        \n=================================================================\nTotal params: 80,651\nTrainable params: 80,651\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"}], "metadata": {"collapsed": false}}, {"execution_count": 25, "cell_type": "code", "source": "# training metrics\nscores = model.evaluate(seq_array, label_array, verbose=2)\nprint('Accurracy: {}'.format(scores[1]))", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Accurracy: 0.9702514234533939\n"}], "metadata": {"collapsed": false}}, {"execution_count": 30, "cell_type": "code", "source": "# make predictions and compute confusion matrix\ny_pred = model.predict_classes(seq_array)\ny_true = label_array\nprint('Confusion matrix\\n- x-axis is true labels.\\n- y-axis is predicted labels')\ncm = confusion_matrix(y_true, y_pred)\ncm", "outputs": [{"output_type": "stream", "name": "stdout", "text": "15631/15631 [==============================] - 10s     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nConfusion matrix\n- x-axis is true labels.\n- y-axis is predicted labels\n"}, {"execution_count": 30, "output_type": "execute_result", "data": {"text/plain": "array([[12226,   305],\n       [  130,  2970]])"}, "metadata": {}}], "metadata": {"collapsed": false}}, {"execution_count": 31, "cell_type": "code", "source": "# compute precision and recall\nprecision = precision_score(y_true, y_pred)\nrecall = recall_score(y_true, y_pred)\nprint( 'precision = ', precision, '\\n', 'recall = ', recall)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "precision =  0.906870229008 \n recall =  0.958064516129\n"}], "metadata": {"collapsed": false}}, {"source": "Next, we look at the performance on the test data. In the [Predictive Maintenance Template Step 1 of 3](https://gallery.cortanaintelligence.com/Experiment/Predictive-Maintenance-Step-1-of-3-data-preparation-and-feature-engineering-2), only the last cycle data for each engine id in the test data is kept for testing purposes. In order to compare the results to the template, we pick the last sequence for each id in the test data.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 32, "cell_type": "code", "source": "seq_array_test_last = [test_df[test_df['id']==id][sequence_cols].values[-sequence_length:] \n                       for id in test_df['id'].unique() if len(test_df[test_df['id']==id]) >= sequence_length]\n\nseq_array_test_last = np.asarray(seq_array_test_last)\nseq_array_test_last.shape", "outputs": [{"execution_count": 32, "output_type": "execute_result", "data": {"text/plain": "(93, 50, 25)"}, "metadata": {}}], "metadata": {"collapsed": false}}, {"execution_count": 33, "cell_type": "code", "source": "y_mask = [len(test_df[test_df['id']==id]) >= sequence_length for id in test_df['id'].unique()]", "outputs": [], "metadata": {"collapsed": true}}, {"source": "Similarly, we pick the labels.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 34, "cell_type": "code", "source": "label_array_test_last = test_df.groupby('id')['label1'].nth(-1)[y_mask].values\nlabel_array_test_last = label_array_test_last.reshape(label_array_test_last.shape[0],1)\nlabel_array_test_last.shape", "outputs": [{"execution_count": 34, "output_type": "execute_result", "data": {"text/plain": "(93, 1)"}, "metadata": {}}], "metadata": {"collapsed": false}}, {"execution_count": 35, "cell_type": "code", "source": "print(seq_array_test_last.shape)\nprint(label_array_test_last.shape)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "(93, 50, 25)\n(93, 1)\n"}], "metadata": {"collapsed": false}}, {"execution_count": 36, "cell_type": "code", "source": "# test metrics\nscores_test = model.evaluate(seq_array_test_last, label_array_test_last, verbose=2)\nprint('Accurracy: {}'.format(scores_test[1]))", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Accurracy: 0.9784946307059257\n"}], "metadata": {"collapsed": false}}, {"execution_count": 37, "cell_type": "code", "source": "# make predictions and compute confusion matrix\ny_pred_test = model.predict_classes(seq_array_test_last)\ny_true_test = label_array_test_last\nprint('Confusion matrix\\n- x-axis is true labels.\\n- y-axis is predicted labels')\ncm = confusion_matrix(y_true_test, y_pred_test)\ncm", "outputs": [{"output_type": "stream", "name": "stdout", "text": "93/93 [==============================] - 0s     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nConfusion matrix\n- x-axis is true labels.\n- y-axis is predicted labels\n"}, {"execution_count": 37, "output_type": "execute_result", "data": {"text/plain": "array([[66,  2],\n       [ 0, 25]])"}, "metadata": {}}], "metadata": {"collapsed": false}}, {"execution_count": 38, "cell_type": "code", "source": "# compute precision and recall\nprecision_test = precision_score(y_true_test, y_pred_test)\nrecall_test = recall_score(y_true_test, y_pred_test)\nf1_test = 2 * (precision_test * recall_test) / (precision_test + recall_test)\nprint( 'Precision: ', precision_test, '\\n', 'Recall: ', recall_test,'\\n', 'F1-score:', f1_test )", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Precision:  0.925925925926 \n Recall:  1.0 \n F1-score: 0.961538461538\n"}], "metadata": {"collapsed": false}}, {"execution_count": 39, "cell_type": "code", "source": "results_df = pd.DataFrame([[scores_test[1],precision_test,recall_test,f1_test],\n                          [0.94, 0.952381, 0.8, 0.869565]],\n                         columns = ['Accuracy', 'Precision', 'Recall', 'F1-score'],\n                         index = ['LSTM',\n                                 'Template Best Model'])\nresults_df", "outputs": [{"execution_count": 39, "output_type": "execute_result", "data": {"text/plain": "                     Accuracy  Precision  Recall  F1-score\nLSTM                 0.978495   0.925926     1.0  0.961538\nTemplate Best Model  0.940000   0.952381     0.8  0.869565", "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th><\/th>\n      <th>Accuracy<\/th>\n      <th>Precision<\/th>\n      <th>Recall<\/th>\n      <th>F1-score<\/th>\n    <\/tr>\n  <\/thead>\n  <tbody>\n    <tr>\n      <th>LSTM<\/th>\n      <td>0.978495<\/td>\n      <td>0.925926<\/td>\n      <td>1.0<\/td>\n      <td>0.961538<\/td>\n    <\/tr>\n    <tr>\n      <th>Template Best Model<\/th>\n      <td>0.940000<\/td>\n      <td>0.952381<\/td>\n      <td>0.8<\/td>\n      <td>0.869565<\/td>\n    <\/tr>\n  <\/tbody>\n<\/table>\n<\/div>"}, "metadata": {}}], "metadata": {"collapsed": false}}, {"source": "Comparing the above test results to the predictive maintenance template, we see that the LSTM results are better than the template. It should be noted that the  data set used here is very small and deep learning models are known to perform superior with large datasets so for a more fair comparison larger datasets should be used.", "cell_type": "markdown", "metadata": {}}, {"source": "## Future Directions and Improvements\nThis tutorial is provided as starting point for using deep learning in predictive maintenance and depending on the data available ", "cell_type": "markdown", "metadata": {}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "3.5.1", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}}}}